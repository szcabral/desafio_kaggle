{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c52a60",
   "metadata": {},
   "source": [
    "## Predição de Sucesso de Startups  \n",
    "\n",
    "Notebook desenvolvido para explorar e modelar dados reais de startups, com foco em prever se uma empresa terá **sucesso (ativa/adquirida)** ou **insucesso (fechada)**.  \n",
    "O projeto envolve análise exploratória, tratamento de valores ausentes, seleção de variáveis e aplicação de modelos de classificação binária, estimulando o uso de técnicas de pré-processamento e aprendizado de máquina aplicadas ao empreendedorismo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227347f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Bibliotecas carregadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35251bd",
   "metadata": {},
   "source": [
    "### 1. Carregamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset principal\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(\"Dados de treino carregados com sucesso. Shape: {}\".format(train_df.shape))\n",
    "print(\"Dados de teste carregados com sucesso. Shape: {}\".format(test_df.shape))\n",
    "\n",
    "print(\"Primeiras 5 linhas dos dados de treino:\")\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Informações gerais sobre os treinos:\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"Estatísticas descritivas dos treinos:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"Valores ausentes nos treinos:\")\n",
    "print(train_df.isnull().sum()[train_df.isnull().sum() > 0])\n",
    "\n",
    "print(\"Distribuição da variável alvo (labels):\")\n",
    "print(train_df[\"labels\"].value_counts())\n",
    "print(train_df[\"labels\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tratando dados ausentes\n",
    "cols_to_impute_median = [\n",
    "    'age_first_funding_year', 'age_last_funding_year',\n",
    "    'age_first_milestone_year', 'age_last_milestone_year',\n",
    "    'funding_total_usd'\n",
    "]\n",
    "\n",
    "for col in cols_to_impute_median:\n",
    "    median_val = train_df[col].median()\n",
    "    train_df[col].fillna(median_val, inplace=True)\n",
    "    test_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(\"Valores ausentes tratados pela mediana para colunas: {}.\".format(cols_to_impute_median))\n",
    "print(\"\\nVerificando valores ausentes após imputação dos treinos:\")\n",
    "print(train_df[cols_to_impute_median].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando one hot encoding para category_code\n",
    "categorical_col = [\"category_code\"]\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=categorical_col, drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_col, drop_first=True)\n",
    "\n",
    "# Alinhamento entre colunas de treino e teste\n",
    "missing_cols_in_test = set(train_df.columns) - set(test_df.columns)\n",
    "missing_cols_in_train = set(test_df.columns) - set(train_df.columns)\n",
    "\n",
    "for col in missing_cols_in_test:\n",
    "    if col != 'labels':  #Evitando coluna alvo em teste\n",
    "        test_df[col] = 0\n",
    "\n",
    "for col in missing_cols_in_train:\n",
    "    if col != 'labels':  #Evitando coluna alvo em treino\n",
    "        train_df[col] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f73400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição e separação de features e target e padronização\n",
    "\n",
    "X_train = train_df.drop(\"labels\", axis=1)\n",
    "y_train = train_df[\"labels\"]\n",
    "\n",
    "X_test = test_df.copy()\n",
    "\n",
    "numerical_cols = [\n",
    "    col for col in X_train.columns\n",
    "    if X_train[col].dtype in [\"int64\", \"float64\"]\n",
    "    and not col.startswith(\"is_\")\n",
    "    and not col.startswith(\"category_code_\")\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Evitar warning com .loc para atribuições diretas\n",
    "X_train.loc[:, numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test.loc[:, numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "print(\"Features e target separados. Colunas numéricas padronizadas.\")\n",
    "print(\"Primeiras 5 linhas de X_train após padronização:\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f773ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando do conjuntos de treinos em treino e validação\n",
    "X_train_full = train_df.drop(\"labels\", axis=1)\n",
    "y_train_full = train_df[\"labels\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5628b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando padronização\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc18388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição para os hiperparâmetros C \n",
    "param_distributions = {'C': np.logspace(-3, 3, 100)}  # valores entre 0.001 e 1000 em escala log\n",
    "\n",
    "logreg = LogisticRegression(random_state=42, solver='liblinear')\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    logreg,\n",
    "    param_distributions,\n",
    "    n_iter=20,          # número de amostras a testar\n",
    "    cv=5,               # folds da validação cruzada\n",
    "    scoring='accuracy',  # métrica para avaliar\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste do conjunto de treino\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Melhor valor de C encontrado: {random_search.best_params_['C']}\")\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "print(\"Relatório de classificação no conjunto de validação:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Acurácia no conjunto de validação: {:.2f}\".format(accuracy_score(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc910a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alinhar colunas para evitar erro no predict\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Previsão no conjunto de teste\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração do arquivo de submissão\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"labels\": predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"../data/submission.csv\", index=False)\n",
    "\n",
    "print(\"Arquivo de submissão gerado com sucesso: ../data/submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
