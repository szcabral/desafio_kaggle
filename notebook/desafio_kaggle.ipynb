{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c52a60",
   "metadata": {},
   "source": [
    "## Predição de Sucesso de Startups  \n",
    "\n",
    "Este notebook tem como objetivo explorar e modelar dados reais de startups para prever se uma empresa terá sucesso (ativa/adquirida) ou insucesso (fechada).\n",
    "\n",
    "O projeto engloba análise exploratória dos dados, tratamento de valores ausentes, seleção de variáveis, processamento e aplicação de modelos de classificação binária."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a888fe",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas\n",
    "\n",
    "Importação das bibliotecas necessárias para manipulação de dados (Pandas, NumPy), visualização (Matplotlib, Seaborn), modelagem (Scikit-Learn) e ajuste de hiperparâmetros (RandomizedSearchCV) e métricas para avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227347f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35251bd",
   "metadata": {},
   "source": [
    "### 2. Carregamento de dados\n",
    "\n",
    "Os datasets de treino e teste são carregados em DataFrames pandas a partir de arquivos CSV. Exibe-se a dimensão, primeiras linhas, informações gerais, estatísticas descritivas e a incidência de valores ausentes para conhecer melhor os dados que se é trabalhado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ddd8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino carregados com sucesso. Shape: (646, 33)\n",
      "Dados de teste carregados com sucesso. Shape: (277, 32)\n",
      "Primeiras 5 linhas dos dados de treino:\n",
      "    id  age_first_funding_year  age_last_funding_year  \\\n",
      "0  719                   10.42                  13.09   \n",
      "1  429                    3.79                   3.79   \n",
      "2  178                    0.71                   2.28   \n",
      "3  197                    3.00                   5.00   \n",
      "4  444                    0.66                   5.88   \n",
      "\n",
      "   age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "0                      8.98                    12.72              4   \n",
      "1                       NaN                      NaN             21   \n",
      "2                      1.95                     2.28              5   \n",
      "3                      9.62                    10.39             16   \n",
      "4                      6.21                     8.61             29   \n",
      "\n",
      "   funding_rounds  funding_total_usd  milestones  is_CA  ...  is_consulting  \\\n",
      "0               3            4087500           3      1  ...              0   \n",
      "1               1           45000000           0      0  ...              0   \n",
      "2               2            5200000           2      1  ...              0   \n",
      "3               2           14500000           2      0  ...              0   \n",
      "4               5           70000000           4      1  ...              0   \n",
      "\n",
      "   is_othercategory  has_VC  has_angel has_roundA  has_roundB  has_roundC  \\\n",
      "0                 0       1          1          0           0           0   \n",
      "1                 0       0          0          0           1           0   \n",
      "2                 1       1          0          1           0           0   \n",
      "3                 0       0          1          0           1           0   \n",
      "4                 0       0          0          1           1           1   \n",
      "\n",
      "   has_roundD  avg_participants  labels  \n",
      "0           0               1.0       0  \n",
      "1           0               1.0       1  \n",
      "2           0               1.0       0  \n",
      "3           0               2.0       1  \n",
      "4           1               2.8       1  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Carregamento do dataset principal\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(\"Dados de treino carregados com sucesso. Shape: {}\".format(train_df.shape))\n",
    "print(\"Dados de teste carregados com sucesso. Shape: {}\".format(test_df.shape))\n",
    "\n",
    "print(\"Primeiras 5 linhas dos dados de treino:\")\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2311629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informações gerais sobre os treinos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 646 entries, 0 to 645\n",
      "Data columns (total 33 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        646 non-null    int64  \n",
      " 1   age_first_funding_year    611 non-null    float64\n",
      " 2   age_last_funding_year     637 non-null    float64\n",
      " 3   age_first_milestone_year  508 non-null    float64\n",
      " 4   age_last_milestone_year   535 non-null    float64\n",
      " 5   relationships             646 non-null    int64  \n",
      " 6   funding_rounds            646 non-null    int64  \n",
      " 7   funding_total_usd         646 non-null    int64  \n",
      " 8   milestones                646 non-null    int64  \n",
      " 9   is_CA                     646 non-null    int64  \n",
      " 10  is_NY                     646 non-null    int64  \n",
      " 11  is_MA                     646 non-null    int64  \n",
      " 12  is_TX                     646 non-null    int64  \n",
      " 13  is_otherstate             646 non-null    int64  \n",
      " 14  category_code             646 non-null    object \n",
      " 15  is_software               646 non-null    int64  \n",
      " 16  is_web                    646 non-null    int64  \n",
      " 17  is_mobile                 646 non-null    int64  \n",
      " 18  is_enterprise             646 non-null    int64  \n",
      " 19  is_advertising            646 non-null    int64  \n",
      " 20  is_gamesvideo             646 non-null    int64  \n",
      " 21  is_ecommerce              646 non-null    int64  \n",
      " 22  is_biotech                646 non-null    int64  \n",
      " 23  is_consulting             646 non-null    int64  \n",
      " 24  is_othercategory          646 non-null    int64  \n",
      " 25  has_VC                    646 non-null    int64  \n",
      " 26  has_angel                 646 non-null    int64  \n",
      " 27  has_roundA                646 non-null    int64  \n",
      " 28  has_roundB                646 non-null    int64  \n",
      " 29  has_roundC                646 non-null    int64  \n",
      " 30  has_roundD                646 non-null    int64  \n",
      " 31  avg_participants          646 non-null    float64\n",
      " 32  labels                    646 non-null    int64  \n",
      "dtypes: float64(5), int64(27), object(1)\n",
      "memory usage: 166.7+ KB\n",
      "Estatísticas descritivas dos treinos:\n",
      "               id  age_first_funding_year  age_last_funding_year  \\\n",
      "count  646.000000              611.000000             637.000000   \n",
      "mean   461.577399                2.341718               4.037724   \n",
      "std    264.859464                2.468275               2.950923   \n",
      "min      1.000000                0.000000               0.000000   \n",
      "25%    233.250000                0.680000               1.870000   \n",
      "50%    459.500000                1.650000               3.610000   \n",
      "75%    692.500000                3.600000               5.590000   \n",
      "max    923.000000               21.900000              21.900000   \n",
      "\n",
      "       age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "count                508.000000               535.000000     646.000000   \n",
      "mean                   3.352657                 4.944729       7.948916   \n",
      "std                    2.866952                 3.213319       7.397602   \n",
      "min                    0.000000                 0.000000       0.000000   \n",
      "25%                    1.185000                 2.540000       3.000000   \n",
      "50%                    2.785000                 4.620000       6.000000   \n",
      "75%                    4.935000                 6.880000      10.000000   \n",
      "max                   24.680000                24.680000      63.000000   \n",
      "\n",
      "       funding_rounds  funding_total_usd  milestones       is_CA  ...  \\\n",
      "count      646.000000       6.460000e+02  646.000000  646.000000  ...   \n",
      "mean         2.351393       2.949633e+07    1.913313    0.546440  ...   \n",
      "std          1.357856       2.261999e+08    1.337095    0.498224  ...   \n",
      "min          1.000000       1.100000e+04    0.000000    0.000000  ...   \n",
      "25%          1.000000       3.000000e+06    1.000000    0.000000  ...   \n",
      "50%          2.000000       1.020000e+07    2.000000    1.000000  ...   \n",
      "75%          3.000000       2.587500e+07    3.000000    1.000000  ...   \n",
      "max          8.000000       5.700000e+09    6.000000    1.000000  ...   \n",
      "\n",
      "       is_consulting  is_othercategory      has_VC   has_angel  has_roundA  \\\n",
      "count     646.000000        646.000000  646.000000  646.000000  646.000000   \n",
      "mean        0.003096          0.304954    0.329721    0.260062    0.515480   \n",
      "std         0.055598          0.460745    0.470476    0.439008    0.500148   \n",
      "min         0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "25%         0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "50%         0.000000          0.000000    0.000000    0.000000    1.000000   \n",
      "75%         0.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "max         1.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "       has_roundB  has_roundC  has_roundD  avg_participants      labels  \n",
      "count  646.000000  646.000000  646.000000        646.000000  646.000000  \n",
      "mean     0.419505    0.235294    0.091331          2.848655    0.647059  \n",
      "std      0.493860    0.424511    0.288303          1.894050    0.478255  \n",
      "min      0.000000    0.000000    0.000000          1.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000          1.500000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000          2.333300    1.000000  \n",
      "75%      1.000000    0.000000    0.000000          4.000000    1.000000  \n",
      "max      1.000000    1.000000    1.000000         16.000000    1.000000  \n",
      "\n",
      "[8 rows x 32 columns]\n",
      "Valores ausentes nos treinos:\n",
      "age_first_funding_year       35\n",
      "age_last_funding_year         9\n",
      "age_first_milestone_year    138\n",
      "age_last_milestone_year     111\n",
      "dtype: int64\n",
      "Distribuição da variável alvo (labels):\n",
      "labels\n",
      "1    418\n",
      "0    228\n",
      "Name: count, dtype: int64\n",
      "labels\n",
      "1    64.705882\n",
      "0    35.294118\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Informações gerais sobre os treinos:\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"Estatísticas descritivas dos treinos:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"Valores ausentes nos treinos:\")\n",
    "print(train_df.isnull().sum()[train_df.isnull().sum() > 0])\n",
    "\n",
    "print(\"Distribuição da variável alvo (labels):\")\n",
    "print(train_df[\"labels\"].value_counts())\n",
    "print(train_df[\"labels\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614246eb",
   "metadata": {},
   "source": [
    "## 3. Tratamento de Valores Ausentes\n",
    "\n",
    "As variáveis numéricas que apresentam dados faltantes (`NaN`), especialmente relacionadas a anos de eventos financeiros e de marcos importantes, são tratadas pela imputação da mediana da respectiva coluna, tanto no treino quanto no teste dos conjuntos de dados.\n",
    "\n",
    "Com isso é mitigado o impacto de valores faltantes sem enviesar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6097bf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48066/2381036111.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_48066/2381036111.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 3. Tratando dados ausentes\n",
    "cols_to_impute_median = [\n",
    "    'age_first_funding_year', 'age_last_funding_year',\n",
    "    'age_first_milestone_year', 'age_last_milestone_year',\n",
    "    'funding_total_usd'\n",
    "]\n",
    "\n",
    "for col in cols_to_impute_median:\n",
    "    median_val = train_df[col].median()\n",
    "    train_df[col].fillna(median_val, inplace=True)\n",
    "    test_df[col].fillna(median_val, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eebd01b",
   "metadata": {},
   "source": [
    "## 4. Codificação de Variáveis Categóricas\n",
    "\n",
    "A variável categórica `category_code` é transformada em variáveis dummy (one-hot encoding), convertendo os setores em colunas binárias para o modelo.  \n",
    "Depois, garante-se o alinhamento entre conjunto de treino e teste, adicionando colunas faltantes com zeros para evitar inconsistências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf78547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando one hot encoding para category_code\n",
    "categorical_col = [\"category_code\"]\n",
    "train_df = pd.get_dummies(train_df, columns=categorical_col, drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_col, drop_first=True)\n",
    "\n",
    "missing_cols_in_test = set(train_df.columns) - set(test_df.columns)\n",
    "missing_cols_in_train = set(test_df.columns) - set(train_df.columns)\n",
    "\n",
    "for col in missing_cols_in_test:\n",
    "    if col != 'labels':\n",
    "        test_df[col] = 0\n",
    "for col in missing_cols_in_train:\n",
    "    if col != 'labels':\n",
    "        train_df[col] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ddb78",
   "metadata": {},
   "source": [
    "## 5. Separação de Features e Target e Padronização\n",
    "\n",
    "Define-se o conjunto de variáveis explicativas (features) e a variável alvo (target).   \n",
    "Selecionam-se as colunas numéricas para padronização usando o StandardScaler, equilibrando a escala dos dados e trazendo melhora para desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f73400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preparação de features e target\n",
    "X_train_full = train_df.drop(\"labels\", axis=1)\n",
    "y_train_full = train_df[\"labels\"]\n",
    "X_test = test_df.copy()\n",
    "\n",
    "numerical_cols = [\n",
    "    col for col in X_train_full.columns\n",
    "    if X_train_full[col].dtype in [\"int64\", \"float64\"]\n",
    "    and not col.startswith(\"is_\")\n",
    "    and not col.startswith(\"category_code_\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7c683",
   "metadata": {},
   "source": [
    "## 6. Divisão em Treino e Validação\n",
    "\n",
    "Divide-se o conjunto de treino original em treino e validação, utilizando uma amostra estratificada para preservar a proporção das classes.  \n",
    "Assim, possibilita avaliação imparcial do modelo antes de validar no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f773ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão treino/validação estratificada\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train_full,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5628b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando padronização\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val_scaled[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec402b",
   "metadata": {},
   "source": [
    "## 7. Ajuste de Hiperparâmetros com RandomizedSearchCV\n",
    "\n",
    "Utiliza-se RandomizedSearchCV para ajustar o hiperparâmetro de regularização C da regressão logística.  \n",
    "Busca aleatória e validação cruzada (5-fold) são aplicadas para encontrar valores que maximizem a acurácia e previnam overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eade365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features antes da seleção: 65\n",
      "Número de features após a seleção: 24\n"
     ]
    }
   ],
   "source": [
    "# Seleção de features baseada em importância com LogisticRegression\n",
    "selector = SelectFromModel(\n",
    "    LogisticRegression(class_weight='balanced', solver='liblinear', max_iter=500, random_state=42),\n",
    "    threshold='mean'\n",
    ")\n",
    "\n",
    "# Ajusta o seletor com treino\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transforma treino e validação normalmente\n",
    "X_train_sel = selector.transform(X_train_scaled)\n",
    "X_val_sel = selector.transform(X_val_scaled)\n",
    "\n",
    "# Para o conjunto de teste, alinhe as colunas de X_test_scaled com as do X_train_scaled\n",
    "X_test_aligned = X_test_scaled[X_train_scaled.columns]\n",
    "\n",
    "# Depois transforme com selector\n",
    "X_test_sel = selector.transform(X_test_aligned)\n",
    "\n",
    "print(f'Número de features antes da seleção: {X_train_scaled.shape[1]}')\n",
    "print(f'Número de features após a seleção: {X_train_sel.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bc18388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Melhor estimador Random Forest: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 20, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Definição para os hiperparâmetros C \n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search_rf.fit(X_train_sel, y_train)\n",
    "\n",
    "print(f'Melhor estimador Random Forest: {random_search_rf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6ca50",
   "metadata": {},
   "source": [
    "## 8. Avaliação do Modelo\n",
    "\n",
    "O melhor modelo encontrado é avaliado no conjunto de validação com métricas completas, incluindo relatório de classificação e acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aced643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de classificação no conjunto de validação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68        46\n",
      "           1       0.83      0.81      0.82        84\n",
      "\n",
      "    accuracy                           0.77       130\n",
      "   macro avg       0.75      0.75      0.75       130\n",
      "weighted avg       0.77      0.77      0.77       130\n",
      "\n",
      "Acurácia no conjunto de validação: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do modelo no conjunto de validação\n",
    "y_val_pred = random_search_rf.predict(X_val_sel)\n",
    "\n",
    "print(\"Relatório de classificação no conjunto de validação:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Acurácia no conjunto de validação: {:.2f}\".format(accuracy_score(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2edb93",
   "metadata": {},
   "source": [
    "## 9. Treinamento Final e Previsão no Conjunto de Teste\n",
    "\n",
    "Treina-se o modelo final com todos os dados de treino utilizando o melhor hiperparâmetro.  \n",
    "Realizam-se as previsões no conjunto de teste, garantindo que as colunas estejam alinhadas com o conjunto de treino, para evitar erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1176cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento final com tudo e predição no teste\n",
    "best_model = random_search_rf.best_estimator_\n",
    "best_model.fit(selector.transform(X_train_full), y_train_full)\n",
    "\n",
    "submission_preds = best_model.predict(X_test_sel)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'labels': submission_preds\n",
    "})\n",
    "\n",
    "submission_df.to_csv('../data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
