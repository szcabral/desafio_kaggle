{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdd919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Bibliotecas carregadas com sucesso\")\n",
    "\n",
    "# 1. Carregamento dos dados (certifique-se que os arquivos estejam no caminho correto)\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(\"Dados de treino carregados com sucesso. Shape: {}\".format(train_df.shape))\n",
    "print(\"Dados de teste carregados com sucesso. Shape: {}\".format(test_df.shape))\n",
    "\n",
    "print(\"\\nPrimeiras 5 linhas dos dados de treino:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# 2. Análise Exploratória de Dados (EDA) Inicial\n",
    "print(\"\\nInformações gerais sobre os dados de treino:\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\nEstatísticas descritivas dos dados de treino:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"\\nValores ausentes nos dados de treino:\")\n",
    "print(train_df.isnull().sum()[train_df.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\nDistribuição da variável alvo (labels):\")\n",
    "print(train_df[\"labels\"].value_counts())\n",
    "print(train_df[\"labels\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "# 3. Tratamento de Valores Ausentes\n",
    "cols_to_impute_median = [\n",
    "    'age_first_funding_year', 'age_last_funding_year',\n",
    "    'age_first_milestone_year', 'age_last_milestone_year',\n",
    "    'funding_total_usd'\n",
    "]\n",
    "\n",
    "for col in cols_to_impute_median:\n",
    "    median_val = train_df[col].median()\n",
    "    train_df[col].fillna(median_val, inplace=True)\n",
    "    test_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(\"Valores ausentes tratados por mediana para as colunas: {}.\".format(cols_to_impute_median))\n",
    "print(\"\\nVerificando valores ausentes após imputação nos dados de treino:\")\n",
    "print(train_df[cols_to_impute_median].isnull().sum())\n",
    "\n",
    "# 4. One-Hot Encoding para category_code\n",
    "categorical_col = [\"category_code\"]\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=categorical_col, drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_col, drop_first=True)\n",
    "\n",
    "# Alinhar colunas de treino e teste (evita problemas quando categorias não aparecem no teste)\n",
    "missing_cols_in_test = set(train_df.columns) - set(test_df.columns)\n",
    "missing_cols_in_train = set(test_df.columns) - set(train_df.columns)\n",
    "\n",
    "for col in missing_cols_in_test:\n",
    "    if col != 'labels':  # Não adicionar a coluna alvo no teste\n",
    "        test_df[col] = 0\n",
    "\n",
    "for col in missing_cols_in_train:\n",
    "    if col != 'labels':  # Não adicionar a coluna alvo no treino\n",
    "        train_df[col] = 0\n",
    "\n",
    "# Reordenar as colunas do teste para ficar igual ao treino\n",
    "test_df = test_df[train_df.drop('labels', axis=1).columns]\n",
    "\n",
    "print(\"One-Hot Encoding aplicado para a coluna {}.\".format(categorical_col[0]))\n",
    "print(\"\\nNovas dimensões dos dados de treino após encoding: {}\".format(train_df.shape))\n",
    "print(\"Novas dimensões dos dados de teste após encoding: {}\".format(test_df.shape))\n",
    "\n",
    "print(\"\\nPrimeiras 5 linhas dos dados de treino após One-Hot Encoding:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# 5. Separação de Features e Target, e Padronização\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = train_df.drop(\"labels\", axis=1)\n",
    "y_train = train_df[\"labels\"]\n",
    "\n",
    "X_test = test_df.copy()\n",
    "\n",
    "numerical_cols = [\n",
    "    col for col in X_train.columns\n",
    "    if X_train[col].dtype in [\"int64\", \"float64\"]\n",
    "    and not col.startswith(\"is_\")\n",
    "    and not col.startswith(\"category_code_\")\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "print(\"Features e target separados. Colunas numéricas padronizadas.\")\n",
    "print(\"\\nPrimeiras 5 linhas de X_train após padronização:\")\n",
    "print(X_train.head())\n",
    "\n",
    "# 6. Treinamento e Avaliação do Modelo (Regressão Logística)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print(\"Modelo de Regressão Logística treinado com sucesso!\")\n",
    "print(\"\\nRelatório de Classificação no conjunto de treino:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"Acurácia no conjunto de treino: {:.2f}\".format(accuracy_score(y_train, y_pred_train)))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Previsões geradas para o conjunto de teste.\")\n",
    "print(\"\\nPrimeiras 5 previsões para o conjunto de teste:\")\n",
    "print(predictions[:5])\n",
    "\n",
    "# 7. Geração do Arquivo de Submissão para o Kaggle\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],  # Certifique-se que há uma coluna \"id\" no test_df\n",
    "    \"labels\": predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"../data/submission.csv\", index=False)\n",
    "\n",
    "print(\"Arquivo de submissão gerado com sucesso: ../data/submission.csv\")\n",
    "print(\"\\nPrimeiras 5 linhas do arquivo de submissão:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
